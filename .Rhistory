#' }
gradientElasticnets <- function(theta, X, y, rho, C){
Z <- X %*% theta
dtheta.l1 <- ifelse(theta>0,1,ifelse(theta<0,-1,0))
gradEN <- (1-rho)*sum(theta)+sum(dtheta.l1)+C*sum(((y*X)*exp(-y*Z)/exp(-y*Z)+1))
#gradEN = grad(logLossElasticnet, x=theta, X = X,y=y,rho=rho,C=C)
return (as.vector(gradEN))
}
gradientElasticnets(theta, X, y, rho=0.1, C=0.2)
#' @param rho hyper parameter which allows arbitration between RDIGE and LASSO
#' @param C parameter allowing to arbitrate between the penalty and the likelihood in the guidance of the modeling
#'
#' @return a vector
#' @export
#'
#' @examples
#' \dontrun{
#'   gradientElasticnet(theta, X, y,l1,l2)
#' }
gradientElasticnets <- function(theta, X, y, rho, C){
Z <- X %*% theta
dtheta.l1 <- ifelse(theta>0,1,ifelse(theta<0,-1,0))
gradEN <- (1-rho)*sum(theta)+sum(dtheta.l1)+C*sum(((y*X)%*%exp(-y*Z)/exp(-y*Z)+1))
#gradEN = grad(logLossElasticnet, x=theta, X = X,y=y,rho=rho,C=C)
return (as.vector(gradEN))
}
gradientElasticnets(theta, X, y, rho=0.1, C=0.2)
#' @param rho hyper parameter which allows arbitration between RDIGE and LASSO
#' @param C parameter allowing to arbitrate between the penalty and the likelihood in the guidance of the modeling
#'
#' @return a vector
#' @export
#'
#' @examples
#' \dontrun{
#'   gradientElasticnet(theta, X, y,l1,l2)
#' }
gradientElasticnets <- function(theta, X, y, rho, C){
#Z <- X %*% theta
#dtheta.l1 <- ifelse(theta>0,1,ifelse(theta<0,-1,0))
#gradEN <- (1-rho)*sum(theta)+sum(dtheta.l1)+C*sum(((y*X)*exp(-y*Z)/exp(-y*Z)+1))
gradEN = grad(logLossElasticnet, x=theta, X = X,y=y,rho=rho,C=C)
return (as.vector(gradEN))
}
usethis::use_package("numDeriv")
logLossElasticnet(runif(3), as.matrix(data[,1:3]), data[,(ncol(data))], 0,0.2)
library(dgrGlm)
logLossElasticnet(runif(3), as.matrix(data[,1:3]), data[,(ncol(data))], 0,0.2)
grad(logLossElasticnet, x=theta, X = as.matrix(data[,1:3]),y=data[,(ncol(data))],rho=0,C=0.2)
gradientElasticnets(theta, X, y, rho=0.1, C=0.2)
grad(logLossElasticnet, x=theta, X = as.matrix(data[,1:3]),y=data[,(ncol(data))],rho=0,C=0.2)
gradientElasticnets(theta, X, y, rho=0.1, C=0.2)
library(dgrGlm)
library(dgrGlm)
# SEQUENTIEL
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-06,
feature_selection=TRUE, p_value=0.01)))
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-06,
iselasticnet = TRUE)))
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-06,
iselasticnet = TRUE, feature_selection=TRUE, p_value=0.01)))
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
leaning_rate=0.5, max_iter=2000,tolerance=1e-06,
iselasticnet = TRUE, feature_selection=TRUE, p_value=0.01)))
model_batch_seq
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-04,
iselasticnet = TRUE, feature_selection=FALSE, p_value=0.01)))
# FONCTION SUMMARY ET PRINT SURCHARGÉ
print(model_batch_seq)
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-04
)))
model_batch_seq
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-04,
iselasticnet=TRUE, C=0.01, rho=0)))
model_batch_seq
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-06,
iselasticnet=TRUE, C=0.01, rho=1)))
# FONCTION SUMMARY ET PRINT SURCHARGÉ
print(model_batch_seq)
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-06,
iselasticnet=TRUE, C=10, rho=1)))
summary(model_batch_parallel)
# PARALLEL
print(system.time(model_batch_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
leaning_rate=0.1, max_iter=1000,tolerance=1e-06,
feature_selection=TRUE, p_value=0.01,
iselasticnet=TRUE, C=10, rho=1)))
library(dgrGlm)
# Gradient sequentiel
print(system.time(model_batch_seq <- dg_batch_seq(X1,y,theta,leaning_rate=0.1, max_iter=100,tolerance=1e-06)))
library(xlsx)
data <- read.xlsx(file="~/Desktop/Lyon2/SISE/AtelierMachLeraning/Reg Logistique_opt_hyp/ionosphere.xlsx",sheetIndex=1,header=T)
data = data[,-33]
# SEQUENTIEL
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-06,
feature_selection=TRUE, p_value=0.01)))
# FONCTION SUMMARY ET PRINT SURCHARGÉ
print(model_batch_seq)
summary(predict)
summary(model_batch_seq)
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-06,
iselasticnet=TRUE, C=10, rho=1)))
print(model_batch_seq)
summary(model_batch_seq)
print(model_batch_seq)
summary(model_batch_seq)
print(system.time(model_batch_seq2 <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-06,
iselasticnet=TRUE, C=10, rho=1)))
print(model_batch_seq2)
summary(model_batch_seq2)
# SEQUENTIEL
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-06,
feature_selection=TRUE, p_value=0.01)))
# FONCTION SUMMARY ET PRINT SURCHARGÉ
print(model_batch_seq)
summary(model_batch_seq)
predict<- dgrglm.predict(model_batch_seq,data[,-ncol(data)])
model_batch_seq
# SEQUENTIEL
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-06,
feature_selection=FALSE, p_value=0.01)))
summary(model_batch_seq)
predict<- dgrglm.predict(model_batch_seq,data[,-ncol(data)])
predict
predict$new_data_classify<- dgrglm.predict(model_batch_seq,data[,-ncol(data)])
predict$new_data_classify
predict$new_data_classify
predict$binary_predict
predict$binary_predict<- dgrglm.predict(model_batch_seq,data[,-ncol(data)],type_pred = 'CLASS')
predict$new_data_classify
predict$new_data_classify
predict
predict$binary_predict<- dgrglm.predict(model_batch_seq,data[,-ncol(data)])
predict<- dgrglm.predict(model_batch_seq,data[,-ncol(data)])
predict$new_data_classify
model_batch_seq
data<-data[,model_batch_seq$explicatives]
data
# SEQUENTIEL
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-06,
feature_selection=TRUE, p_value=0.01)))
library(xlsx)
data <- read.xlsx(file="~/Desktop/Lyon2/SISE/AtelierMachLeraning/Reg Logistique_opt_hyp/ionosphere.xlsx",sheetIndex=1,header=T)
data = data[,-33]
# SEQUENTIEL
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-06,
feature_selection=TRUE, p_value=0.01)))
new_data<-data[,model_batch_seq$explicatives]
predict$new_data_classify<- dgrglm.predict(model_batch_seq,new_data)
new_data<-data[,model_batch_seq$explicatives]
predict<- dgrglm.predict(model_batch_seq,new_data)
predict$new_data_classify
summary(model_batch_seq)
# FONCTION SUMMARY ET PRINT SURCHARGÉ
print(model_batch_seq2)
summary(model_batch_seq2)
# PARALLEL
print(system.time(model_batch_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
leaning_rate=0.1, max_iter=1000,tolerance=1e-06,
feature_selection=TRUE, p_value=0.01,
iselasticnet=TRUE, C=10, rho=1)))
print(model_batch_parallel)
summary(model_batch_parallel)
library(dgrGlm)
model_batch_parallel
# PARALLEL
print(system.time(model_batch_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
leaning_rate=0.1, max_iter=1000,tolerance=1e-06,
feature_selection=TRUE, p_value=0.01,
iselasticnet=TRUE, C=0.1, rho=0)))
print(model_batch_parallel)
# PARALLEL
print(system.time(model_batch_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
leaning_rate=0.1, max_iter=1000,tolerance=1e-06,
iselasticnet=TRUE, C=0.1, rho=0)))
# PARALLEL
print(system.time(model_batch_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
leaning_rate=0.1, max_iter=1000,tolerance=1e-06,
iselasticnet=TRUE, C=0.1, rho=0)))
print(model_batch_parallel)
summary(model_batch_parallel)
print(system.time(model_minibatch_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
batch_size = 100,leaning_rate=0.1, max_iter=1000,tolerance=1e-06)))
model_online_parallel
model_minibatch_parallel
# PARALLEL
print(system.time(model_batch_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-06,
iselasticnet=TRUE, C=0.1, rho=0.001)))
model_batch_parallel
# PARALLEL
print(system.time(model_batch_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-06,
iselasticnet=TRUE, C=10, rho=0.001)))
model_minibatch_parallel
print(system.time(model_online_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
batch_size = 1,leaning_rate=0.1, max_iter=100,tolerance=1e-06)))
model_online_seq
model_online_parallel
print(system.time(model_online_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
batch_size = 1,leaning_rate=0.1, max_iter=1000,tolerance=1e-06)))
model_minibatch_parallel
model_online_parallel
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_minibatch_parallel$probas,model_online_parallel$probas,model_online_parallel$y_val[,1])
# FONCTION UTILITAIRE POUR COMPARER DEUX MODÉLE AVEC UNE COURBE ROC
compare_model<- function(probas_mod1, probas_mod2, y){
predProbas <- data.frame(model1=probas_mod1, model2=probas_mod2)
# Estimation des classes en fonctions des probas
predClass <- apply(predProbas >= 0.5, 2, factor, labels=c(0,1))
predClass <- data.frame(predClass)
# Erreur de classification des deux modéles
df_err<- predClass %>%
mutate(obs=y) %>%
summarise_all(funs(err=mean(obs!=.))) %>%
select(-obs_err) %>%
round(3)
# Etude des courbes ROC
df_roc <- predProbas %>%
mutate(obs=y) %>%
gather(key = methode, value=score, model1, model2)
toPlot<- ggplot(df_roc)+
aes(d=obs,m=score, color=methode)+
geom_roc()+
theme_classic()
return(list(predProbas = predProbas, PredClass = predClass, models_error = df_err,  toPlot=toPlot))
}
library(tidyverse)
library(plotROC)
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_minibatch_parallel$probas,model_online_parallel$probas,model_online_parallel$y_val[,1])
model_online_parallel$probas
model_minibatch_parallel$probas
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_minibatch_parallel$probas,model_online_parallel$probas,model_online_parallel$y_val[,1])
library(tidyverse)
library(plotROC)
# FONCTION UTILITAIRE POUR COMPARER DEUX MODÉLE AVEC UNE COURBE ROC
compare_model<- function(probas_mod1, probas_mod2, y){
predProbas <- data.frame(model1=probas_mod1, model2=probas_mod2)
# Estimation des classes en fonctions des probas
predClass <- apply(predProbas >= 0.5, 2, factor, labels=c(0,1))
predClass <- data.frame(predClass)
# Erreur de classification des deux modéles
df_err<- predClass %>%
mutate(obs=y) %>%
summarise_all(funs(err=mean(obs!=.))) %>%
select(-obs_err) %>%
round(3)
# Etude des courbes ROC
df_roc <- predProbas %>%
mutate(obs=y) %>%
gather(key = methode, value=score, model1, model2)
toPlot<- ggplot(df_roc)+
aes(d=obs,m=score, color=methode)+
geom_roc()+
theme_classic()
return(list(predProbas = predProbas, PredClass = predClass, models_error = df_err,  toPlot=toPlot))
}
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_batch_seq$probas,model_online_parallel$probas,model_online_parallel$y_val[,1])
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_batch_seq$probas,model_batch_seq$probas,model_online_parallel$y_val[,1])
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_batch_seq$probas,model_batch_seq$probas,model_batch_seq$y_val[,1])
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_batch_seq$probas,model_batch_parallel$probas,model_batch_seq$y_val[,1])
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_batch_seq$probas,model_batch_parallel$probas,model_batch_seq$y_val[,1])
model_minibatch_parallel$y_val[,1]
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_minibatch_parallel$probas,model_online_parallel$probas,model_minibatch_parallel$y_val[,1])
library(tidyverse)
library(plotROC)
# FONCTION UTILITAIRE POUR COMPARER DEUX MODÉLE AVEC UNE COURBE ROC
compare_model<- function(probas_mod1, probas_mod2, y){
predProbas <- data.frame(model1=probas_mod1, model2=probas_mod2)
# Estimation des classes en fonctions des probas
predClass <- apply(predProbas >= 0.5, 2, factor, labels=c(0,1))
predClass <- data.frame(predClass)
# Erreur de classification des deux modéles
df_err<- predClass %>%
mutate(obs=y) %>%
summarise_all(funs(err=mean(obs!=.))) %>%
select(-obs_err) %>%
round(3)
# Etude des courbes ROC
df_roc <- predProbas %>%
mutate(obs=y) %>%
gather(key = methode, value=score, model1, model2)
toPlot<- ggplot(df_roc)+
aes(d=obs,m=score, color=methode)+
geom_roc()+
theme_classic()
return(list(predProbas = predProbas, PredClass = predClass, models_error = df_err,  toPlot=toPlot))
}
# FONCTION UTILITAIRE POUR COMPARER DEUX MODÉLE AVEC UNE COURBE ROC
compare_model<- function(probas_mod1, probas_mod2, y){
predProbas <- data.frame(model1=probas_mod1, model2=probas_mod2)
# Estimation des classes en fonctions des probas
predClass <- apply(predProbas >= 0.5, 2, factor, labels=c(0,1))
predClass <- data.frame(predClass)
# Erreur de classification des deux modéles
df_err<- predClass %>%
mutate(obs=y) %>%
summarise_all(funs(err=mean(obs!=.))) %>%
select(obs_err) %>%
round(3)
# Etude des courbes ROC
df_roc <- predProbas %>%
mutate(obs=y) %>%
gather(key = methode, value=score, model1, model2)
toPlot<- ggplot(df_roc)+
aes(d=obs,m=score, color=methode)+
geom_roc()+
theme_classic()
return(list(predProbas = predProbas, PredClass = predClass, models_error = df_err,  toPlot=toPlot))
}
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_minibatch_parallel$probas,model_online_parallel$probas,model_minibatch_parallel$y_val[,1])
# FONCTION UTILITAIRE POUR COMPARER DEUX MODÉLE AVEC UNE COURBE ROC
compare_model<- function(probas_mod1, probas_mod2, y){
predProbas <- data.frame(model1=probas_mod1, model2=probas_mod2)
# Estimation des classes en fonctions des probas
predClass <- apply(predProbas >= 0.5, 2, factor, labels=c(0,1))
predClass <- data.frame(predClass)
# Erreur de classification des deux modéles
df_err<- predClass %>%
mutate(obs=y) %>%
summarise_all(funs(err=mean(obs!=.))) %>%
round(3)
# Etude des courbes ROC
df_roc <- predProbas %>%
mutate(obs=y) %>%
gather(key = methode, value=score, model1, model2)
toPlot<- ggplot(df_roc)+
aes(d=obs,m=score, color=methode)+
geom_roc()+
theme_classic()
return(list(predProbas = predProbas, PredClass = predClass, models_error = df_err,  toPlot=toPlot))
}
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_minibatch_parallel$probas,model_online_parallel$probas,model_minibatch_parallel$y_val[,1])
perf
# FONCTION UTILITAIRE POUR COMPARER DEUX MODÉLE AVEC UNE COURBE ROC
compare_model<- function(probas_mod1, probas_mod2, y){
predProbas <- data.frame(model1=probas_mod1, model2=probas_mod2)
# Estimation des classes en fonctions des probas
predClass <- apply(predProbas >= 0.5, 2, factor, labels=c(0,1))
predClass <- data.frame(predClass)
# Erreur de classification des deux modéles
df_err<- predClass %>%
mutate(obs=y) %>%
summarise_all(funs(err=mean(obs!=.))) %>%
select(-obs_err) %>%
round(3)
# Etude des courbes ROC
df_roc <- predProbas %>%
mutate(obs=y) %>%
gather(key = methode, value=score, model1, model2)
toPlot<- ggplot(df_roc)+
aes(d=obs,m=score, color=methode)+
geom_roc()+
theme_classic()
return(list(predProbas = predProbas, PredClass = predClass, models_error = df_err,  toPlot=toPlot))
}
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_minibatch_parallel$probas,model_online_parallel$probas,model_minibatch_parallel$y_val[,1])
model_minibatch_parallel
model_minibatch_parallel
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_minibatch_parallel$probas,model_online_parallel$probas,model_online_parallel$y_val[,1])
# FONCTION UTILITAIRE POUR COMPARER DEUX MODÉLE AVEC UNE COURBE ROC
compare_model<- function(probas_mod1, probas_mod2, y){
predProbas <- data.frame(model1=probas_mod1, model2=probas_mod2)
# Estimation des classes en fonctions des probas
predClass <- apply(predProbas >= 0.5, 2, factor, labels=c(0,1))
predClass <- data.frame(predClass)
# Erreur de classification des deux modéles
df_err<- predClass %>%
mutate(obs=y) %>%
summarise_all(funs(err=mean(obs!=.))) %>%
#select(-obs_err) %>%
round(3)
# Etude des courbes ROC
df_roc <- predProbas %>%
mutate(obs=y) %>%
gather(key = methode, value=score, model1, model2)
toPlot<- ggplot(df_roc)+
aes(d=obs,m=score, color=methode)+
geom_roc()+
theme_classic()
return(list(predProbas = predProbas, PredClass = predClass, models_error = df_err,  toPlot=toPlot))
}
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_minibatch_parallel$probas,model_online_parallel$probas,model_online_parallel$y_val[,1])
perf$toPlot
model_online_parallel
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model1=model_minibatch_parallel$probas,
model2=model_online_parallel$probas,
model_online_parallel$y_val[,1])
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_minibatch_parallel$probas,
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
compare_model
perf$toPlot
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_batch_parallel$probas,
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_minibatch_parallel$probas,
probas_mod2=model_batch_parallel$probas,
y=model_online_parallel$y_val[,1])
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_minibatch_parallel$probas,
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_batch_seq$probas,
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
perf$toPlot
model_batch_seq
print(system.time(model_online_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
batch_size = 1,leaning_rate=0.1, max_iter=100,tolerance=1e-06)))
model_online_parallel
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_batch_seq$probas,
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
perf$toPlot
# PARALLEL
print(system.time(model_batch_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
leaning_rate=0.1, max_iter=100,tolerance=1e-06,
iselasticnet=TRUE, C=10, rho=0.001)))
print(system.time(model_minibatch_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
batch_size = 100,leaning_rate=0.1, max_iter=100,tolerance=1e-06)))
model_batch_parallel
model_minibatch_parallel
model_online_parallel
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_batch_parallel$probas,
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
model_batch_parallel$probas
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=as.vector(model_batch_parallel$probas),
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
model_online_parallel$probas
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_minibatch_parallel$probas,
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
perf$toPlot
print(system.time(model_minibatch_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
batch_size = 100,leaning_rate=0.1, max_iter=3000,tolerance=1e-06)))
model_minibatch_parallel
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_minibatch_parallel$probas,
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
perf$toPlot
remove.packages("dgrGlm")
library(devtools)
install_github("Beuleup93/dgrGlm", dependencies = TRUE)
library(dgrGlm)
?dgrglm.fit
?dgrglm.fit
install_github("Beuleup93/dgrGlm", dependencies = TRUE)
install_github("Beuleup93/dgrGlm", dependencies = TRUE,force = TRUE)
library(dgrGlm)
?dgrglm.fit
remove.packages("dgrGlm")
install_github("Beuleup93/dgrGlm", dependencies = TRUE)
library(dgrGlm)
install_github("Beuleup93/dgrGlm", dependencies = TRUE)
library(dgrGlm)
?dgrglm.predict
remove.packages("dgrGlm")
install_github("Beuleup93/dgrGlm")
detach("package:dgrGlm", unload = TRUE)
library(dgrGlm)
?dgrglm.fit
library(xlsx)
data <- read.xlsx(file="~/Desktop/Lyon2/SISE/AtelierMachLeraning/Reg Logistique_opt_hyp/ionosphere.xlsx",sheetIndex=1,header=T)
data = data[,-33]
# SEQUENTIEL
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-06,
feature_selection=TRUE, p_value=0.01)))
detach("package:dgrGlm", unload = TRUE)
remove.packages("dgrGlm")
library(dgrGlm)
