dataset$V5<- na.aggregate(dataset$V4, FUN = mean)
any(is.na(as.numeric(dataset$V4)))
dataset$V4<- na.aggregate(dataset$V4, FUN = mean)
for(i in 1:ncol(dataset)){
if(is.numeric(dataset[,i])){
dataset[is.na(dataset[,i]), i] <- mean(dataset[,i], na.rm = TRUE)
}
}
for(i in 1:ncol(dataset)){
if(is.numeric(dataset[,i])){
dataset[is.na(dataset[,i]), i] <- mean(dataset[,i], na.rm = TRUE)
print("ok")
}
}
for(i in 1:ncol(dataset)){
if(is.numeric(dataset[,i])){
dataset[is.na(dataset[,i]), i] <- mean(dataset[,i], na.rm = TRUE)
print(i)
}
}
dataset[is.na(dataset[,i]), i] <- mean(dataset[,i], na.rm = TRUE)
dataset
for(i in 1:ncol(dataset)){
if(is.numeric(dataset[,i])){
dataset[is.na(dataset[,i]), i] <- mean(dataset[,i], na.rm = TRUE)
print(i)
}
}
dataset2 <- dataset
for(i in 1:ncol(dataset2)){
if(is.numeric(dataset2[,i])){
dataset2[is.na(dataset2[,i]), i] <- mean(dataset2[,i], na.rm = TRUE)
print(i)
}
}
View(dataset2)
dataset2 <- dataset
for(i in 1:ncol(dataset2)){
if(is.numeric(dataset2[,i])){
dataset[,i]<- na.aggregate(dataset[,i], FUN = mean)
}
}
dataset <- CommViolPredUnnormalizedData <- read.csv("~/Downloads/CommViolPredUnnormalizedData.txt", header=FALSE, stringsAsFactors = TRUE)
head(dataset)
str(dataset)
# La fonction aggr représente le pourcentage de valeur manquante dans chaque variable
# Et nous avons aussi les combinaisons de variable qui ont des valeurs manquantes simultanés
# La combinaisons la plus fréquente est celle ou toute les variables sont observées, toutes les cases sont bleux(ligne du bas)
# Vu que le mécanisme de données manquante est aléatoire, nous pouvons:
# Soit l'imputation simple ou à valeur unique si l'objectif est de prévoir au mieu les valeurs manquantes.
dataset[dataset == '?'] <- NA
# Nombre de ligne avec des données manquantes
nrow(na.omit(dataset))
dataset2 <- dataset
for(i in 1:ncol(dataset2)){
if(is.numeric(dataset2[,i])){
dataset2[,i]<- na.aggregate(dataset2[,i], FUN = mean)
}
}
View(dataset2)
# Nombre de ligne avec des données manquantes
nrow(na.omit(dataset))
dataset2 <- dataset
for(i in 1:ncol(dataset2)){
if(is.numeric(dataset2[,i])){
dataset2[,i]<- na.aggregate(dataset2[,i], FUN = mean)
print(i)
}
}
any(is.na(as.numeric(dataset$V5)))
any(is.na(as.numeric(dataset$V6)))
any(is.na(as.numeric(dataset$V7)))
dataset <- CommViolPredUnnormalizedData <- read.csv("~/Downloads/CommViolPredUnnormalizedData.txt", header=FALSE, stringsAsFactors = TRUE)
head(dataset)
str(dataset)
# Nombre de ligne avec des données manquantes
nrow(na.omit(dataset))
# La fonction aggr représente le pourcentage de valeur manquante dans chaque variable
# Et nous avons aussi les combinaisons de variable qui ont des valeurs manquantes simultanés
# La combinaisons la plus fréquente est celle ou toute les variables sont observées, toutes les cases sont bleux(ligne du bas)
# Vu que le mécanisme de données manquante est aléatoire, nous pouvons:
# Soit l'imputation simple ou à valeur unique si l'objectif est de prévoir au mieu les valeurs manquantes.
dataset[dataset == '?'] <- NA
# Nombre de ligne avec des données manquantes
nrow(na.omit(dataset))
any(is.na(as.numeric(dataset$V7)))
any(is.na(dataset$V5))
any(is.na(dataset$V5))
all(is.na(dataset$V5))
dataset
View(dataset)
any(is.na(dataset$V104))
dataset2 <- dataset
for(i in 1:ncol(dataset2)){
if(is.numeric(dataset2[,i])){
dataset2[,i]<- na.aggregate(dataset2[,i], FUN = mean)
print(i)
}
}
res<- summary(aggr(dataset2, sortVar=TRUE))$combinations
res
for(i in 1:ncol(dataset2)){
if(is.numeric(dataset2[,i])){
dataset2[,i]<- na.aggregate(dataset2[,i], FUN = mean)
print(i)
}
}
dataset2 <- dataset
dataset <- CommViolPredUnnormalizedData <- read.csv("~/Downloads/CommViolPredUnnormalizedData.txt", header=FALSE, stringsAsFactors = TRUE)
head(dataset)
str(dataset)
View(dataset)
# La fonction aggr représente le pourcentage de valeur manquante dans chaque variable
# Et nous avons aussi les combinaisons de variable qui ont des valeurs manquantes simultanés
# La combinaisons la plus fréquente est celle ou toute les variables sont observées, toutes les cases sont bleux(ligne du bas)
# Vu que le mécanisme de données manquante est aléatoire, nous pouvons:
# Soit l'imputation simple ou à valeur unique si l'objectif est de prévoir au mieu les valeurs manquantes.
dataset[dataset == '?'] <- NA
# Nombre de ligne avec des données manquantes
nrow(na.omit(dataset))
# Remplacer les données manquantes par leurs moyenne
# Imputation des données manquantes par la moyenne
library(zoo)
dataset
for(i in 1:ncol(dataset)){
if(is.numeric(dataset[,i]) && is.na(dataset[,i])){
dataset[,i]<- na.aggregate(dataset[,i], FUN = mean)
print(i)
}
else{
print(i)
}
}
dataset
for(i in 1:ncol(dataset)){
if(is.numeric(dataset[,i])){
dataset[,i] = ifelse(is.na(dataset[,i]),
ave(dataset[,i], FUN = function(x) mean(x, na.rm = TRUE)),
dataset[,i])
}
}
View(dataset)
dataset
VisaPremier <- read.csv("~/Desktop/Lyon2/SISE/Projet R/VisaPremier.csv", stringsAsFactors=TRUE)
View(VisaPremier)
dataset <- read.csv("~/Desktop/Lyon2/SISE/Projet R/VisaPremier.csv", stringsAsFactors=TRUE)
head(dataset)
library("VIM") # cette librairie permet de visualiser le dispositif de données manquante
# La fonction aggr représente le pourcentage de valeur manquante dans chaque variable
# Et nous avons aussi les combinaisons de variable qui ont des valeurs manquantes simultanés
# La combinaisons la plus fréquente est celle ou toute les variables sont observées, toutes les cases sont bleux(ligne du bas)
# Vu que le mécanisme de données manquante est aléatoire, nous pouvons:
# Soit l'imputation simple ou à valeur unique si l'objectif est de prévoir au mieu les valeurs manquantes.
dataset[dataset == '?'] <- NA
# Nombre de ligne avec des données manquantes
nrow(na.omit(dataset))
str(dataset)
# Nombre de ligne avec des données manquantes
nrow(na.omit(dataset))
res<- summary(aggr(dataset, sortVar=TRUE))$combinations
dataset$V4<- na.aggregate(dataset$V4, FUN = mean)
View(dataset)
#dataset[,i] = ifelse(is.na(dataset[,i]),
#ave(dataset[,i], FUN = function(x) mean(x, na.rm = TRUE)),
# dataset[,i])
print(is(dataset[,i]))
#dataset[,i] = ifelse(is.na(dataset[,i]),
#ave(dataset[,i], FUN = function(x) mean(x, na.rm = TRUE)),
# dataset[,i])
print(is.na(dataset[,i]))
for(i in 1:ncol(dataset)){
if(is.numeric(dataset[,i])){
#dataset[,i] = ifelse(is.na(dataset[,i]),
#ave(dataset[,i], FUN = function(x) mean(x, na.rm = TRUE)),
# dataset[,i])
print(is.na(dataset[,i]))
}
}
table(dataset$cartevp )
dataset$cartevp = factor(dataset$cartevp,
levels = c('Cnon', 'Cyes'),
labels = c(0, 1))
dataset$cartevp
table(dataset$cartevp)
dataset$cartevp
dataset <- read.csv("~/Desktop/Lyon2/SISE/Projet R/VisaPremier.csv", stringsAsFactors=TRUE)
head(dataset)
str(dataset)
dataset$cartevp
dataset$cartevp = factor(dataset$cartevp,
levels = c('Cnon', 'Cyes'),
labels = c(0, 1))
table(dataset$cartevp)
dataset$cartevp = factor(dataset$cartevp,
levels = c('Cnon', 'Coui'),
labels = c(0, 1))
table(dataset$cartevp)
dataset <- read.csv("~/Desktop/Lyon2/SISE/Projet R/VisaPremier.csv", stringsAsFactors=TRUE)
head(dataset)
str(dataset)
View(dataset)
dataset$cartevp = factor(dataset$cartevp,
levels = c('Cnon', 'Coui'),
labels = c(0, 1))
table(dataset$cartevp)
table(dataset$sexe)
table(dataset$sexer)
dataset$sexe = factor(dataset$cartevp,
levels = c('Sfem', 'Shom'),
labels = c(0, 1))
dataset$sexe
dataset$sexe = factor(dataset$sexe,
levels = c('Sfem', 'Shom'),
labels = c(0, 1))
dataset$sexe
dataset <- read.csv("~/Desktop/Lyon2/SISE/Projet R/VisaPremier.csv", stringsAsFactors=TRUE)
head(dataset)
str(dataset)
dataset$cartevp = factor(dataset$cartevp,
levels = c('Cnon', 'Coui'),
labels = c(0, 1))
dataset$sexe = factor(dataset$sexe,
levels = c('Sfem', 'Shom'),
labels = c(0, 1))
dataset$sexe
# La fonction aggr représente le pourcentage de valeur manquante dans chaque variable
# Et nous avons aussi les combinaisons de variable qui ont des valeurs manquantes simultanés
# La combinaisons la plus fréquente est celle ou toute les variables sont observées, toutes les cases sont bleux(ligne du bas)
# Vu que le mécanisme de données manquante est aléatoire, nous pouvons:
# Soit l'imputation simple ou à valeur unique si l'objectif est de prévoir au mieu les valeurs manquantes.
dataset[dataset == '.'] <- NA
# Nombre de ligne avec des données manquantes
nrow(na.omit(dataset))
res<- summary(aggr(dataset, sortVar=TRUE))$combinations
str(dataset)
Mode(dataset$nbpaiecb)
mode(dataset$nbpaiecb)
sapply(iris, Mode, na.rm=TRUE)
getmode <- function(v) {
uniqv <- unique(v)
uniqv[which.max(tabulate(match(v, uniqv)))]
}
getode(dataset$nbpaiecb)
getmode(dataset$nbpaiecb)
getmode <- function(v) {
uniqv <- unique(v)
return(uniqv[which.max(tabulate(match(v, uniqv)))])
}
getmode(dataset$nbpaiecb)
install.packages("DescTools")
library(DescTools)
mode(dataset$nbpaiecb)
Mode(dataset$nbpaiecb)
Mode(dataset$codeqlt)
library(zoo)
library(DescTools)
dataset$nbpaiecb <- na.aggregate(dataset$nbpaiecb, FUN = Mode)
dataset$codeqlt <- na.aggregate(dataset$codeqlt, FUN = Mode)
dataset$departem <- na.aggregate(dataset$departem, FUN = Mode)
dataset$agemvt <- na.aggregate(dataset$agemvt, FUN = Mode)
res<- summary(aggr(dataset, sortVar=TRUE))$combinations
dataset
Mode(dataset$codeqlt)
library(tidyverse)
dataset.quali
str(dataset)
quali<- sapply(dataset, function(x) is.numeric(x) or is.integer(x))
quali<- sapply(dataset, function(x) is.numeric(x) | is.integer(x))
quali
dataset[quali]
sep_var<- sapply(dataset, function(x) is.numeric(x) | is.integer(x))
quali = colnames(dataset[sep_var==TRUE])
quali
quanti = colnames(dataset[sep_var==TRUE])
quanti = colnames(dataset[sep_var==FALSE])
quanti
table(dataset$nbpaiecb)
str(dataset)
table(dataset$nbpaiecb)
res<- summary(aggr(dataset, sortVar=TRUE))$combinations
dataset <- read.csv("~/Desktop/Lyon2/SISE/Projet R/VisaPremier.csv", stringsAsFactors=TRUE)
head(dataset)
str(dataset)
# La fonction aggr représente le pourcentage de valeur manquante dans chaque variable
# Et nous avons aussi les combinaisons de variable qui ont des valeurs manquantes simultanés
# La combinaisons la plus fréquente est celle ou toute les variables sont observées, toutes les cases sont bleux(ligne du bas)
# Vu que le mécanisme de données manquante est aléatoire, nous pouvons:
# Soit l'imputation simple ou à valeur unique si l'objectif est de prévoir au mieu les valeurs manquantes.
dataset[dataset == '.'] <- NA
res<- summary(aggr(dataset, sortVar=TRUE))$combinations
library(zoo)
library(DescTools)
dataset$nbpaiecb <- na.aggregate(dataset$nbpaiecb, FUN = Mode)
dataset$codeqlt <- na.aggregate(dataset$codeqlt, FUN = Mode)
dataset$departem <- na.aggregate(dataset$departem, FUN = Mode)
dataset$agemvt <- na.aggregate(dataset$agemvt, FUN = Mode)
res<- summary(aggr(dataset, sortVar=TRUE))$combinations
sep_var<- sapply(dataset, function(x) is.numeric(x) | is.integer(x))
quanti = colnames(dataset[sep_var==TRUE])
quanti = colnames(dataset[sep_var==FALSE])
quanti
quali = colnames(dataset[sep_var==TRUE])
quanti = colnames(dataset[sep_var==FALSE])
quali
quali = colnames(dataset[sep_var==TRUE])
quali
dataset$cartevp = factor(dataset$cartevp,
levels = c('Cnon', 'Coui'),
labels = c(0, 1))
dataset$sexe = factor(dataset$sexe,
levels = c('Sfem', 'Shom'),
labels = c(0, 1))
sep_var<- sapply(dataset, function(x) is.numeric(x) | is.integer(x))
quali = colnames(dataset[sep_var==TRUE])
quanti = colnames(dataset[sep_var==FALSE])
quali = colnames(dataset[sep_var==TRUE])
quali
quanti = colnames(dataset[sep_var==TRUE])
quali = colnames(dataset[sep_var==FALSE])
quali
df = select(dataset, quali)
View(df)
df2 = select(dataset, quanti)
df2 = select(dataset, all_of(quanti))
df = select(dataset, all_of(quali))
df1 = select(dataset, all_of(quali))
df2 = select(dataset, all_of(quanti))
View(df1)
View(df2)
table(dataset$nbpaiecb)
as.numeric(dataset$nbpaiecb)
dataset <- read.csv("~/Desktop/Lyon2/SISE/Projet R/VisaPremier.csv", stringsAsFactors=TRUE)
head(dataset)
str(dataset)
# La fonction aggr représente le pourcentage de valeur manquante dans chaque variable
# Et nous avons aussi les combinaisons de variable qui ont des valeurs manquantes simultanés
# La combinaisons la plus fréquente est celle ou toute les variables sont observées, toutes les cases sont bleux(ligne du bas)
# Vu que le mécanisme de données manquante est aléatoire, nous pouvons:
# Soit l'imputation simple ou à valeur unique si l'objectif est de prévoir au mieu les valeurs manquantes.
dataset[dataset == '.'] <- NA
# Nombre de ligne avec des données manquantes
nrow(na.omit(dataset))
res<- summary(aggr(dataset, sortVar=TRUE))$combinations
dataset$cartevp = factor(dataset$cartevp,
levels = c('Cnon', 'Coui'),
labels = c(0, 1))
dataset$sexe = factor(dataset$sexe,
levels = c('Sfem', 'Shom'),
labels = c(0, 1))
as.numeric(dataset$nbpaiecb)
dataset$nbpaiecb <- na.aggregate(dataset$nbpaiecb, FUN = Mode)
dataset$codeqlt <- na.aggregate(dataset$codeqlt, FUN = Mode)
dataset$departem <- na.aggregate(dataset$departem, FUN = Mode)
dataset$agemvt <- na.aggregate(dataset$agemvt, FUN = Mode)
dataset$nbpaiecb
dataset <- read.csv("~/Desktop/Lyon2/SISE/Projet R/VisaPremier.csv", stringsAsFactors=TRUE)
head(dataset)
str(dataset)
# La fonction aggr représente le pourcentage de valeur manquante dans chaque variable
# Et nous avons aussi les combinaisons de variable qui ont des valeurs manquantes simultanés
# La combinaisons la plus fréquente est celle ou toute les variables sont observées, toutes les cases sont bleux(ligne du bas)
# Vu que le mécanisme de données manquante est aléatoire, nous pouvons:
# Soit l'imputation simple ou à valeur unique si l'objectif est de prévoir au mieu les valeurs manquantes.
dataset[dataset == '.'] <- NA
res<- summary(aggr(dataset, sortVar=TRUE))$combinations
dataset$cartevp = factor(dataset$cartevp,
levels = c('Cnon', 'Coui'),
labels = c(0, 1))
dataset$sexe = factor(dataset$sexe,
levels = c('Sfem', 'Shom'),
labels = c(0, 1))
as.numeric(dataset$nbpaiecb)
dataset$nbpaiecb <- na.aggregate(dataset$nbpaiecb, FUN = mean)
dataset$codeqlt <- na.aggregate(dataset$codeqlt, FUN = Mode)
dataset$departem <- na.aggregate(dataset$departem, FUN = Mode)
dataset$agemvt <- na.aggregate(dataset$agemvt, FUN = Mode)
dataset$nbpaiecb
dataset$codeqlt
res<- summary(aggr(dataset, sortVar=TRUE))$combinations
dataset$nbpaiecb <- na.aggregate(as.numeric(dataset$nbpaiecb), FUN = mean)
dataset$codeqlt <- na.aggregate(dataset$codeqlt, FUN = Mode)
dataset$departem <- na.aggregate(dataset$departem, FUN = Mode)
dataset$agemvt <- na.aggregate(dataset$agemvt, FUN = Mode)
dataset$nbpaiecb
dataset <- read.csv("~/Desktop/Lyon2/SISE/Projet R/VisaPremier.csv", stringsAsFactors=TRUE)
head(dataset)
str(dataset)
library("VIM") # cette librairie permet de visualiser le dispositif de données manquante
# La fonction aggr représente le pourcentage de valeur manquante dans chaque variable
# Et nous avons aussi les combinaisons de variable qui ont des valeurs manquantes simultanés
# La combinaisons la plus fréquente est celle ou toute les variables sont observées, toutes les cases sont bleux(ligne du bas)
# Vu que le mécanisme de données manquante est aléatoire, nous pouvons:
# Soit l'imputation simple ou à valeur unique si l'objectif est de prévoir au mieu les valeurs manquantes.
dataset[dataset == '.'] <- NA
nrow(na.omit(dataset))
res<- summary(aggr(dataset, sortVar=TRUE))$combinations
dataset$cartevp = factor(dataset$cartevp,
levels = c('Cnon', 'Coui'),
labels = c(0, 1))
dataset$sexe = factor(dataset$sexe,
levels = c('Sfem', 'Shom'),
labels = c(0, 1))
library(zoo)
library(DescTools)
dataset$nbpaiecb <- na.aggregate(as.integer(dataset$nbpaiecb), FUN = mean)
dataset$codeqlt <- na.aggregate(dataset$codeqlt, FUN = Mode)
dataset$departem <- na.aggregate(dataset$departem, FUN = Mode)
dataset$agemvt <- na.aggregate(dataset$agemvt, FUN = Mode)
dataset$nbpaiecb
sep_var<- sapply(dataset, function(x) is.numeric(x) | is.integer(x))
quanti = colnames(dataset[sep_var==TRUE])
quali = colnames(dataset[sep_var==FALSE])
df1 = select(dataset, all_of(quali))
df2 = select(dataset, all_of(quanti))
df2 = select(dataset, all_of(quanti))
View(df2)
df2 = df2[, c((ncol(df2)-1), (ncol(df2)-2))]
View(df2)
View(df2)
df1 = select(dataset, all_of(quali))
df2 = select(dataset, all_of(quanti))
df2 = df2[, c(-(ncol(df2)-1), -(ncol(df2)-2))]
View(df2)
data = select(dataset, colnames(df2), all_of(quali))
View(data)
rows <- sample(nrow(data))
data <- data[rows, ]
View(data)
# Caret
library(caret)
names(getModelInfo())
?train
?trainControl
train_control<- trainControl(method="cv", number=5)
reg.glm = train(cartevp~.,
data=data,
method="glm",
trControl=train_control)
warnings()
?train
train_control<- trainControl(method="cv", number=5)
reg.glm = train(cartevp~.,
data=data,
method="glm",
maxit=1000,
trControl=train_control)
warnings()
View(data)
table(data$sitfamil)
col
#table(data$sitfamil)
#table(data$csp)
#table(data$codeqlt)
col = colnames(data)
col
View(data)
data = data[, c(-(ncol(data)-2), -(ncol(data)-3), -(ncol(data)-4))]
View(data)
train_control<- trainControl(method="cv", number=5)
reg.glm = train(cartevp~.,
data=data,
method="glm",
maxit=1000,
trControl=train_control)
train_control<- trainControl(method="cv", number=5)
reg.glm = train(cartevp~.,
data=data,
method="glm",
trControl=train_control)
print(reg.glm)
print(reg.glm$finalModel)
?createDataPartition
print(length(trainIndex))
print(length(trainIndex))
trainIndex <- ?createDataPartition(data$cartevp, p=0.7, list= F)
print(length(trainIndex))
# Create partition
set.seed(12)
trainIndex <- createDataPartition(data$cartevp, p=0.7, list= F)
print(length(trainIndex))
str(data)
train = data[trainIndex,]
test = data[-trainIndex,]
View(train)
train_control<- trainControl(method="cv", number=5)
reg.glm = train(cartevp~.,
data=train,
method="glm",
maxit=1000,
trControl=train_control)
print(reg.glm)
print(reg.glm$finalModel)
pred = predict(reg.glm, newdata = test)
pred = predict(reg.glm, newdata = test)
pred
length(pred)
print(table(pred))
# Matrice de confusion
mat<- confusionMatrix(data=pred, reference=data$cartevp)
# Matrice de confusion
mat<- confusionMatrix(data=pred, reference=data$cartevp, positive=1)
mat<- confusionMatrix(data=pred, reference=data$cartevp, positive=1)
print(mat)
# Matrice de confusion
mat<- confusionMatrix(data=pred, reference=data$cartevp, positive=1)
# Matrice de confusion
mat<- confusionMatrix(data=pred, reference=data$cartevp, positive=1)
?confusionMatrix
# Matrice de confusion
mat<- ?confusionMatrix(reference=data$cartevp, data=pred, positive=1)
print(mat)
print(mat)
