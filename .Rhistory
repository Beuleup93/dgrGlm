predClass <- data.frame(predClass)
# Erreur de classification des deux modéles
df_err<- predClass %>%
mutate(obs=y) %>%
summarise_all(funs(err=mean(obs!=.))) %>%
round(3)
# Etude des courbes ROC
df_roc <- predProbas %>%
mutate(obs=y) %>%
gather(key = methode, value=score, model1, model2)
toPlot<- ggplot(df_roc)+
aes(d=obs,m=score, color=methode)+
geom_roc()+
theme_classic()
return(list(predProbas = predProbas, PredClass = predClass, models_error = df_err,  toPlot=toPlot))
}
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_minibatch_parallel$probas,model_online_parallel$probas,model_minibatch_parallel$y_val[,1])
perf
# FONCTION UTILITAIRE POUR COMPARER DEUX MODÉLE AVEC UNE COURBE ROC
compare_model<- function(probas_mod1, probas_mod2, y){
predProbas <- data.frame(model1=probas_mod1, model2=probas_mod2)
# Estimation des classes en fonctions des probas
predClass <- apply(predProbas >= 0.5, 2, factor, labels=c(0,1))
predClass <- data.frame(predClass)
# Erreur de classification des deux modéles
df_err<- predClass %>%
mutate(obs=y) %>%
summarise_all(funs(err=mean(obs!=.))) %>%
select(-obs_err) %>%
round(3)
# Etude des courbes ROC
df_roc <- predProbas %>%
mutate(obs=y) %>%
gather(key = methode, value=score, model1, model2)
toPlot<- ggplot(df_roc)+
aes(d=obs,m=score, color=methode)+
geom_roc()+
theme_classic()
return(list(predProbas = predProbas, PredClass = predClass, models_error = df_err,  toPlot=toPlot))
}
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_minibatch_parallel$probas,model_online_parallel$probas,model_minibatch_parallel$y_val[,1])
model_minibatch_parallel
model_minibatch_parallel
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_minibatch_parallel$probas,model_online_parallel$probas,model_online_parallel$y_val[,1])
# FONCTION UTILITAIRE POUR COMPARER DEUX MODÉLE AVEC UNE COURBE ROC
compare_model<- function(probas_mod1, probas_mod2, y){
predProbas <- data.frame(model1=probas_mod1, model2=probas_mod2)
# Estimation des classes en fonctions des probas
predClass <- apply(predProbas >= 0.5, 2, factor, labels=c(0,1))
predClass <- data.frame(predClass)
# Erreur de classification des deux modéles
df_err<- predClass %>%
mutate(obs=y) %>%
summarise_all(funs(err=mean(obs!=.))) %>%
#select(-obs_err) %>%
round(3)
# Etude des courbes ROC
df_roc <- predProbas %>%
mutate(obs=y) %>%
gather(key = methode, value=score, model1, model2)
toPlot<- ggplot(df_roc)+
aes(d=obs,m=score, color=methode)+
geom_roc()+
theme_classic()
return(list(predProbas = predProbas, PredClass = predClass, models_error = df_err,  toPlot=toPlot))
}
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model_minibatch_parallel$probas,model_online_parallel$probas,model_online_parallel$y_val[,1])
perf$toPlot
model_online_parallel
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(model1=model_minibatch_parallel$probas,
model2=model_online_parallel$probas,
model_online_parallel$y_val[,1])
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_minibatch_parallel$probas,
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
compare_model
perf$toPlot
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_batch_parallel$probas,
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_minibatch_parallel$probas,
probas_mod2=model_batch_parallel$probas,
y=model_online_parallel$y_val[,1])
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_minibatch_parallel$probas,
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_batch_seq$probas,
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
perf$toPlot
model_batch_seq
print(system.time(model_online_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
batch_size = 1,leaning_rate=0.1, max_iter=100,tolerance=1e-06)))
model_online_parallel
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_batch_seq$probas,
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
perf$toPlot
# PARALLEL
print(system.time(model_batch_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
leaning_rate=0.1, max_iter=100,tolerance=1e-06,
iselasticnet=TRUE, C=10, rho=0.001)))
print(system.time(model_minibatch_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
batch_size = 100,leaning_rate=0.1, max_iter=100,tolerance=1e-06)))
model_batch_parallel
model_minibatch_parallel
model_online_parallel
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_batch_parallel$probas,
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
model_batch_parallel$probas
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=as.vector(model_batch_parallel$probas),
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
model_online_parallel$probas
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_minibatch_parallel$probas,
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
perf$toPlot
print(system.time(model_minibatch_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
batch_size = 100,leaning_rate=0.1, max_iter=3000,tolerance=1e-06)))
model_minibatch_parallel
# EVALUATE PERFORMANCE MODEL
perf <- compare_model(probas_mod1=model_minibatch_parallel$probas,
probas_mod2=model_online_parallel$probas,
y=model_online_parallel$y_val[,1])
perf$toPlot
remove.packages("dgrGlm")
library(devtools)
install_github("Beuleup93/dgrGlm", dependencies = TRUE)
library(dgrGlm)
?dgrglm.fit
?dgrglm.fit
install_github("Beuleup93/dgrGlm", dependencies = TRUE)
install_github("Beuleup93/dgrGlm", dependencies = TRUE,force = TRUE)
library(dgrGlm)
?dgrglm.fit
remove.packages("dgrGlm")
install_github("Beuleup93/dgrGlm", dependencies = TRUE)
library(dgrGlm)
install_github("Beuleup93/dgrGlm", dependencies = TRUE)
library(dgrGlm)
?dgrglm.predict
remove.packages("dgrGlm")
install_github("Beuleup93/dgrGlm")
detach("package:dgrGlm", unload = TRUE)
library(dgrGlm)
?dgrglm.fit
library(xlsx)
data <- read.xlsx(file="~/Desktop/Lyon2/SISE/AtelierMachLeraning/Reg Logistique_opt_hyp/ionosphere.xlsx",sheetIndex=1,header=T)
data = data[,-33]
# SEQUENTIEL
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=2000,tolerance=1e-06,
feature_selection=TRUE, p_value=0.01)))
detach("package:dgrGlm", unload = TRUE)
remove.packages("dgrGlm")
library(dgrGlm)
library(dgrGlm)
set.seed(103)
n <-10000  # Number of obervations
p <- 5 # Number of variables
theta = runif(p+1) # Theta vector
X <- cbind(1,matrix(rnorm(n*p),n,p))
Z <- X %*% theta # linear combination of variables
fprob <- ifelse(Z<0, exp(Z)/(1+exp(Z)),1/(1+exp(-Z))) # Calcul des probas d'affectation
y<- rbinom(n,1,fprob)
data = as.data.frame(cbind(X,y))
data$V1 <- NULL
# EXECUTION TIME
print(system.time(model_batch_parallel <- dgrglm.fit(y~., data = data, ncores=3, mode_compute="parallel",
leaning_rate=0.1, max_iter=100,tolerance=1e-06)))
# EXECUTION TIME
print(system.time(model_batch_parallel <- dgrglm.fit(y~., data = data, mode_compute="parallel",
leaning_rate=0.1, max_iter=100,tolerance=1e-06)))
summary(model_batch_parallel)
# EXECUTION TIME
print(system.time(model_batch_parallel <- dgrglm.fit(y~., data = data, mode_compute="parallel",
leaning_rate=0.1, max_iter=100,tolerance=1e-06, centering = TRUE)))
model_batch_parallel$archive_EctMoy
model_batch_parallel$explicatives
model_batch_parallel$probas
# EXECUTION TIME
print(system.time(model_batch_parallel <- dgrglm.fit(y~., data = data, mode_compute="parallel",
leaning_rate=0.1, max_iter=100,tolerance=1e-06, centering = TRUE)))
library(dgrGlm)
model_batch_parallel$archive_EctMoy
predict<- dgrglm.predict(model_batch_seq,new_data, type_pred = 'CLASS')
predict<- dgrglm.predict(model_batch_parallel,data, type_pred = 'CLASS')
predict<- dgrglm.predict(model_batch_parallel,data[,-(ncol(data))], type_pred = 'CLASS')
predict
predict$new_data_classify
set.seed(103)
n <-10000  # Number of obervations
p <- 5 # Number of variables
theta = runif(p+1) # Theta vector
X <- cbind(1,matrix(rnorm(n*p),n,p))
Z <- X %*% theta # linear combination of variables
fprob <- ifelse(Z<0, exp(Z)/(1+exp(Z)),1/(1+exp(-Z))) # Calcul des probas d'affectation
y<- rbinom(n,1,fprob)
data = as.data.frame(cbind(X,y))
data$V1 <- NULL # delete colomn de biais. It will be created when fit is called
library(microbenchmark)
microbenchmark(
model_batch_seq <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=500,tolerance=1e-04),
model_minibatch_seq <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",leaning_rate=0.1,
max_iter=500,tolerance=1e-04,batch_size = 10),
model_online_seq <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=500,tolerance=1e-04, batch_size = 1),
times = 1,
unit = "s"
)
set.seed(103)
n <-100000  # Number of obervations
p <- 5 # Number of variables
theta = runif(p+1) # Theta vector
X <- cbind(1,matrix(rnorm(n*p),n,p))
Z <- X %*% theta # linear combination of variables
fprob <- ifelse(Z<0, exp(Z)/(1+exp(Z)),1/(1+exp(-Z))) # Calcul des probas d'affectation
y<- rbinom(n,1,fprob)
data = as.data.frame(cbind(X,y))
data$V1 <- NULL # delete colomn de biais. It will be created when fit is called
# SEQUENTIEL EXECUTION TIME
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=1000,tolerance=1e-04)))
print(system.time(model_batch_seq2 <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=1000,tolerance=1e-04,
iselasticnet=TRUE, C=10, rho=1)))
print(system.time(model_minibatch_seq <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
batch_size = 100,leaning_rate=0.1,
max_iter=2000,tolerance=1e-04)))
print(system.time(model_batch_seq <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
leaning_rate=0.1, max_iter=1000,tolerance=1e-04)))
print(system.time(model_minibatch_seq <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
batch_size = 100,leaning_rate=0.1,
max_iter=2000,tolerance=1e-04)))
print(system.time(model_minibatch_seq <- dgrglm.fit(y~., data = data, mode_compute="sequentiel",
batch_size = 100,leaning_rate=0.1,
max_iter=1000,tolerance=1e-04)))
library(dgrGlm)
#vider la m?moire
rm(list=ls())
#r?pertoire de travail
setwd("/Users/macbookair/Desktop/Lyon2/SISE/TextMining/data_seance_2")
#package XML
library(XML)
document <- htmlParse(file="brel-vesoul.html")
print(class(document))
print(document)
#Exploration arborescente du document
#recuperation de la racine du document
racine <- xmlRoot(document)
print(racine)
#le noeud body
b2 <- racine[["body"]]
print(b2)
#decomposition en paragraphes
#la recherche de la balise <p>
textes <- xpathApply(b2,path="p",xmlValue)
print(textes)
textes <- xpathApply(b2,path="p",xmlValue)
print(textes)
vec.textes <- unlist(textes)
print(vec.textes)
docs <- gsub("\r\n"," ",vec.textes)
print(docs)
#package tm
library(tm)
#transf. en VectorSource.... ? vous la suite....
vsdocs <- VectorSource(docs)
class(vsdocs)
vsdocs
print(vsdocs$content)
attributes(vsdocs)
attributes(vsdocs)
vsdocs$position
vsdocs[vsdocs$position==2]
vsdocs$content[2]
vsdocs <- Corpus(vsdocs)
vsdocs
#transf. en VectorSource.... ? vous la suite....
vsdocs <- VectorSource(docs)
class(vsdocs) # "VectorSource" "SimpleSource" "Source"
# pour acceder aux attributs
attributes(vsdocs)
print(vsdocs$content)
# 2 eme paragraphe
vsdocs$content[2]
# Transformer vsdocs en corpus
corpus <- Corpus(vsdocs)
#class
class(corpus)
attributes(corpus)
corpus$content
corpus[3]
corpus$content[3]
#5
tm_map(corpus)
?tm_map
#5
tm_map(corpus, FUN = tolower)
#5
tm_map(corpus, FUN = tolower())
#5
corpus <- tm_map(corpus, content_transformer(tolower))
#transf. en VectorSource.... ? vous la suite....
vsdocs <- VectorSource(docs)
class(vsdocs) # "VectorSource" "SimpleSource" "Source"
# pour acceder aux attributs
attributes(vsdocs)
print(vsdocs$content)
# 2 eme paragraphe
vsdocs$content[2]
# Transformer vsdocs en corpus
corpus <- Corpus(vsdocs)
#class
class(corpus) #"SimpleCorpus" "Corpus"
attributes(corpus)
print(corpus$content)
corpus$content[3] # Af
#5
corpus <- tm_map(corpus, content_transformer(tolower))
#6 Matrice documents termes
mdt1 <- DocumentTermMatrix()
#6 Matrice documents termes
mdt1 <- DocumentTermMatrix(corpus)
corpus
corpus$content[3]
#6 Matrice documents termes
mdt1 <- DocumentTermMatrix(corpus)
class(mdt1)
print(mdt1)
attributes(mdt1)
mdt1$v
mdt1$i
mdt1$i
mdt1$j
mdt1$ncol
# Nombre de
mdt1$class
attributes(mdt1)
# Nombre de
mdt1$tf
# Nombre de
mdt1$dimnames
# findFreqTermes
findFreqTerms(mdt1)
# findFreqTermes
findFreqTerms(mdt10,20)
?findFreqTerms
# findFreqTermes
findFreqTerms(tdm, 1, 20)
# findFreqTermes
findFreqTerms(mdt1, 1, 20)
# findFreqTermes
findFreqTerms(mdt1, 20, )
# Les termes correlés avec mere
?findAssocs()
# Les termes correlés avec mere
findAssocs(mdt1,"mere", 0.99)
# 10
M1 <- as.matrix(mdt1)
attributes(M1)
# Indiquons la liste des termes du dictionnaire
colnames(M1)
# Nombre d'apparition de chaque terme
M1$dimnames$Terms
# Nombre d'apparition de chaque terme
M1$Terms
# Nombre d'apparition de chaque terme
M1$dimnames
# 10
M1 <- as.matrix(mdt1)
# Nombre d'apparition de chaque terme
M1$dimnames
# Nombre d'apparition de chaque terme
M1 <- table(M1)
# 10
M1 <- as.matrix(mdt1)
table(M1)
# Nombre d'apparition de chaque terme
M1
# Nombre d'apparition de chaque terme
findFreqTerms(M1)
# 10
M1 <- as.matrix(mdt1)
# Nombre d'apparition de chaque terme
tmp <- DocumentTermMatrix(M1)
# Nombre d'apparition de chaque terme
M1
# Nombre d'apparition de chaque terme
colSums(M1)
# Nombre d'apparition de chaque terme
sort(colSums(M1))
# Nombre d'apparition de chaque terme
sort(colSums(M1),descending=TRUE)
# Nombre d'apparition de chaque terme
sort(colSums(M1),decreasing=TRUE)
# Nombre d'apparition de chaque terme
class(sort(colSums(M1),decreasing=TRUE))
# Nombre d'apparition de chaque terme
nb <- sort(colSums(M1),decreasing=TRUE)
# Nombre d'apparition de chaque terme
nb <- sort(colSums(M1),decreasing=TRUE)
# Les 20 termes les plus fréquents
head(nb)
# Les 20 termes les plus fréquents
term20Freq <- head(nb,20)
term20Freq
wordcloud::wordcloud()
term20Freq
library(wordcloud)
wordcloud(words = colnames(term20Freq), freq = term20Freq[1,], min.freq = 1,
max.words=97, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
colnames(term20Freq)
term20Freq
term20Freq[1,]
# Les 20 termes les plus fréquents
term20Freq <- head(nb,20)
term20Freq <- as.data.frame(term20Freq)
term20Freq
rowna(term20Freq)
rownames(term20Freq)
wordcloud(words = rownames(term20Freq), freq = term20Freq$term20Freq, min.freq = 1,
max.words=97, random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
M1
M1[which(3)]
M1[which(M1)==3]
M1[which(M1, 3)]
M1[which(M1)=3]
M1
M1[3,]
tmp <- M1[3,]
tmp
tmp <- which(M1[3,])
M1[3,]
tmp <- M1[3,]
which(M1[3,])
termFreq(corpus$content[3])
rowsum(termFreq(corpus$content[3]))
termFreq(corpus$content[3])
sum(termFreq(corpus$content[3]))
doc3 <- corpus$content[3]
plusUtilise <- as.data.frame(termFreq(doc3))
plusUtilise
mdt12 <- DocumentTermMatrix(doc3)
doc3 <- corpus$content[3]
mdt12 <- DocumentTermMatrix(doc3)
corpus
doc3 <- corpus$content[3]
plusUtilise <- as.data.frame(termFreq(doc3))
sort(plusUtilise, decreasing = TRUE)
plusUtilise <- as.data.frame(termFreq(doc3))
sort(plusUtilise, decreasing = TRUE)
sort(plusUtilise)
plusUtilise
?sort
sort(termFreq(doc3), decreasing = TRUE)
sort(plusUtilise, decreasing = TRUE)
#
print(sort(colnames(M1)[which(M1[3,]>0)]))
# VERIFICATION
print(termFreq(corpus$content[[3]]))
library(dgrGlm)
setwd("~/Downloads")
breast <- read.csv("~/Downloads/breast.csv", sep=";")
View(breast)
model_batch_parallel <- dgrglm.fit(class~., data = breast, ncores=3, mode_compute="parallel",
leaning_rate=0.1, max_iter=100,tolerance=1e-06)
model_batch_parallel <- dgrglm.fit(class~., data = breast, mode_compute="parallel",
leaning_rate=0.1, max_iter=100,tolerance=1e-06)
summary(model_batch_parallel)
print(model_batch_parallel)
print(system.time(model_online_parallel <- dgrglm.fit(class~., data = breast, ncores=3, mode_compute="parallel",
batch_size = 100,leaning_rate=0.1, max_iter=100,
tolerance=1e-06)))
print(system.time(model_online_parallel <- dgrglm.fit(class~., data = breast, ncore=3, mode_compute="parallel",
batch_size = 100,leaning_rate=0.1, max_iter=100,
tolerance=1e-06)))
print(system.time(model_online_parallel <- dgrglm.fit(class~., data = breast, ncore=4, mode_compute="parallel",
batch_size = 100,leaning_rate=0.1, max_iter=100,
tolerance=1e-06)))
print(system.time(model_batch_parallel <- dgrglm.fit(class~., data = breast, mode_compute="parallel",
leaning_rate=0.1, max_iter=100,tolerance=1e-06)))
print(system.time(model_batch_parallel <- dgrglm.fit(class~., data = breast, ncores=4, mode_compute="parallel",
leaning_rate=0.1, max_iter=100,tolerance=1e-06)))
print(system.time(model_online_parallel <- dgrglm.fit(class~., data = breast, ncores=4, mode_compute="parallel",
batch_size = 100,leaning_rate=0.1, max_iter=100,
tolerance=1e-06)))
model_online_parallel
model_batch_parallel
print(system.time(model_online_parallel <- dgrglm.fit(class~., data = breast, ncores=4, mode_compute="parallel",
batch_size = 200,leaning_rate=0.1, max_iter=100,
tolerance=1e-06)))
model_online_parallel
